{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b49521-61be-425b-b2a9-469888613a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "145f1959-6a3b-4450-8141-6f844e34f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, max, min, sum, mean\n",
    "# from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e2285c-acdf-4431-b49a-a948a983c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ScalaToPySpark\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca9edb92-c8f9-4041-b418-cfe15c4334dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JDBC connection properties\n",
    "jdbc_hostname = \"localhost\"\n",
    "jdbc_port = 3306\n",
    "jdbc_url = f\"jdbc:mysql://{jdbc_hostname}:{jdbc_port}/information_schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b20942c-6ab2-46a2-955b-064efbb111b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"Root@123\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4825d6cb-b554-402c-aa2d-c2b0fa83c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select SCHEMA_NAME to avoid unsupported MySQL column types\n",
    "df_databases = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"(SELECT SCHEMA_NAME FROM SCHEMATA) AS dbs\",\n",
    "    properties=connection_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c21a87-0e25-4dae-932b-492c6511b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|SCHEMA_NAME       |\n",
      "+------------------+\n",
      "|mysql             |\n",
      "|information_schema|\n",
      "|performance_schema|\n",
      "|sys               |\n",
      "|sparkdb           |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_databases.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b884c6e-8dd0-4b95-b2a0-e81e22475d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to sparkdb\n",
    "database = \"sparkdb\"\n",
    "jdbc_url_sparkdb = f\"jdbc:mysql://{jdbc_hostname}:{jdbc_port}/{database}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e071185-ff73-47ca-b7ef-40c44aa494b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp = spark.read.jdbc(\n",
    "    url=jdbc_url_sparkdb,\n",
    "    table=\"emp\",  # table name in sparkdb\n",
    "    properties=connection_properties\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb90472-e582-4edb-b843-766bb9a0f532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+-----+\n",
      "|empid|      ename| esal|\n",
      "+-----+-----------+-----+\n",
      "|  100|    Abhiran|14000|\n",
      "|  101|     Bhavya|24000|\n",
      "|  102|    Aravind|54000|\n",
      "|  103|   Mohanlal|34000|\n",
      "|  104|     Rakesh|84000|\n",
      "|  105|      Danya|58000|\n",
      "|  106|      Eswar|29000|\n",
      "|  107|     Faisal|19000|\n",
      "|  108|     Venkat|74000|\n",
      "|  109| RajVardhan|87000|\n",
      "|  110|  SekharRaj|56000|\n",
      "|  111|    Mounika|39000|\n",
      "|  112|    Vardhan|64000|\n",
      "|  113|    Richard|68000|\n",
      "|  114|      Bruce|96000|\n",
      "|  115|   Balamani|49000|\n",
      "|  116|RamChandran|27000|\n",
      "|  117|   Rajsekar|88000|\n",
      "|  118|     Ravali|68000|\n",
      "|  119|      Nasal|50000|\n",
      "+-----+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1b666e-9d21-4335-91ef-3a3ef195212d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6321525-02b8-49b8-8b3d-f2c580884c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp.write.mode(\"overwrite\").csv(\"file:///C:/Users/aksha/Pyspark/df_emp_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96f420dd-ece6-4de2-b49e-123798357100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp.write.mode(\"overwrite\").json(\"file:///C:/Users/aksha/Pyspark/df_emp_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac4b3e3a-355a-40e9-8c57-7e6190218162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|empid|     ename| esal|\n",
      "+-----+----------+-----+\n",
      "|  108|    Venkat|74000|\n",
      "|  112|   Vardhan|64000|\n",
      "|  110| SekharRaj|56000|\n",
      "|  113|   Richard|68000|\n",
      "|  118|    Ravali|68000|\n",
      "|  104|    Rakesh|84000|\n",
      "|  117|  Rajsekar|88000|\n",
      "|  109|RajVardhan|87000|\n",
      "|  119|     Nasal|50000|\n",
      "|  105|     Danya|58000|\n",
      "|  114|     Bruce|96000|\n",
      "|  115|  Balamani|49000|\n",
      "|  102|   Aravind|54000|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.filter(col(\"esal\") > 40000).orderBy(col(\"ename\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3727cb74-8bc4-4127-bb0d-695238e113ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empid: integer (nullable = true)\n",
      " |-- ename: string (nullable = true)\n",
      " |-- esal: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f90f037-5fd8-437f-9b7b-81fb39b1d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_url = \"jdbc:mysql://localhost:3306/sparkdb\"  # Target YOUR database\n",
    "connection_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"Root@123\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cc427d6-bf8e-445a-98b3-60bff2e889b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a new table named \"high_salary_employees\"\n",
    "df_emp.write.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=\"resulttab\",  # New table name\n",
    "        mode=\"overwrite\",               # Options: \"overwrite\", \"append\", \"ignore\", \"error\"\n",
    "        properties=connection_properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb82bfa3-f917-4043-b1db-a9b52ef01507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc45e74-d3aa-40b2-8c32-b53d4fac7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"select count(*) from batchi28.parttable\").show() when connected to hive and access database and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b18c7-daad-46a1-8651-37e221e935b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"create table testtab(cid int,cnam string,cheadcnt int,cloc string\") row format delimited fields terminated by '|' lines terminated by '\\n'\n",
    "#stored as textfile location 'hdfs:localhost:8020/user/hive/warehouse/testtab').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa598976-aac4-4d76-a683-458c21e260b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"load dta local inpath'file:///............../empdata.log'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a9c7a-75c6-463f-9913-8388dd71fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(range(1,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241bb7c-b9dd-4842-89a3-8237fcd40efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdata = data.map(lambda x:(x,x*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d1789-cd4b-4bbe-8c3a-ab675bf2958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mapdata.toDF([\"number\",\"Square\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800bbec-0f82-494b-8f92-9aafd0d17338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf6da0-b150-454a-8506-c5232bb0208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.write.saveAsTable(\"Hivetab20\") #Directly saves the table in the hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87090b-4c30-4676-b2aa-bdcefbe247b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hive \n",
    "#show databases\n",
    "#show tables in batch128  here batch128 is a database name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f9d90-e98f-431e-8b43-ed19b50905de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to configure hive in spark environment so that we can access the hive environment and its data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f331d-9106-47c3-943e-c4c5f512f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"show tables in batch128\").show() this is the query in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f420471-135b-4090-9f37-f91fb0909de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hive integration with spark sql\n",
    "#Step 1: We have to copy metastore configuration file of hive to Spark Conf dir \n",
    "#Step 2: We have to copy Hadoop master node information(metadata info of storage) to Spark Conf dir  - core-site.xml\n",
    "#Step 3: We have to copy back up mechanism info of Hadoop to Spark Conf dir - hdfs-site.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf04214-b8cf-41da-858e-5fb44ff23347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"select count(*) from batch128.tablename\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf21cc-6931-4e58-beac-77feef114a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38780d-f9c4-4e5b-9a98-35cc5427f9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3.11",
   "language": "python",
   "name": "pyspark3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
