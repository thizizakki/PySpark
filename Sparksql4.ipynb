{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed45cf9-c37f-4d1d-8145-c5211c8d2cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42c2c69-0578-48ca-bb4e-7958c6e48b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, max, min, sum, mean, explode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce663be3-7fd7-4ad2-bd0d-db3dbe468604",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"ScalaToPySpark\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d8b02d-b64a-4397-9bfe-73159034a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(range(1,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa888656-0c0c-42d5-a490-1f496d4f7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdata = data.map(lambda x:(x,x*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c06ae49-2512-4a9c-a0f3-61d39698c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mapdata.toDF([\"number\",\"Square\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c70596-ecee-4d13-9015-e77c1e7a2d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|number|Square|\n",
      "+------+------+\n",
      "|     1|     1|\n",
      "|     2|     4|\n",
      "|     3|     9|\n",
      "|     4|    16|\n",
      "|     5|    25|\n",
      "|     6|    36|\n",
      "|     7|    49|\n",
      "|     8|    64|\n",
      "|     9|    81|\n",
      "|    10|   100|\n",
      "|    11|   121|\n",
      "|    12|   144|\n",
      "|    13|   169|\n",
      "|    14|   196|\n",
      "|    15|   225|\n",
      "|    16|   256|\n",
      "|    17|   289|\n",
      "|    18|   324|\n",
      "|    19|   361|\n",
      "|    20|   400|\n",
      "+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718bfc11-93b3-4c75-aecb-b05e4632cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the data into hive \n",
    "#df.write.saveAsTable(\"hivetable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935f6375-b866-4103-ba6b-6b159a6a2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To write the data into specified database\n",
    "#df.coalesce(1).write.mode(\"overwrite\").saveAsTable(classdb.hivetable) # By default it will save the file in a paraquette format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "053528f5-1eea-48e8-ac96-efe69d0757d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hive commands\n",
    "#show databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c6ac44-9d57-46ae-8b2f-6e3319e514e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"drop database sparkdb CASCADE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94086da1-b237-4cee-9853-5fd268178c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"create database sparkdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "521dbccb-4b29-4a98-8056-c45546dc348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"create table if not exists sparkdb.empdetails(empId int, name string, loc string, pannum string, yrsofexp float,skillset string)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6750cca6-75c5-4f13-aa06-7604d26e72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"Load data local inpath file:///C:/Users/aksha/Pyspark/empdetails.csv\" overwrite into table sparkdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "101edd72-2258-47d3-9739-996cc7f7fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.format(\"csv\").option(\"header\",\"false\").option(\"delimiter\",\"\\t\").load(\"file:///C:/Users/aksha/Pyspark/tabData.log\").selectExpr(\"_c0 as ID\",\"_c1 as NAME\",\"_c2 as SAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d512ab9-8231-4a2e-a238-c2833c06060a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f822443-0e8d-4308-aadc-b5e9d381f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|   ID|   NAME|    SAL|\n",
      "+-----+-------+-------+\n",
      "|EMPID|  ENAME|ESALARY|\n",
      "| 1111|  VVRaj|  12000|\n",
      "| 1331|Krishna|  14000|\n",
      "| 1551|   Mike|  16000|\n",
      "| 1002|  Ramya|  24000|\n",
      "| 1900| Rakesh|  34000|\n",
      "| 1455| Dr.Ali|  90000|\n",
      "| 8005|Mounika|  24000|\n",
      "| 1006| Sourav|  26000|\n",
      "| 1007|   Siya|  98000|\n",
      "| 1008| Bhavya|  30000|\n",
      "| 1009|Trinath|  34000|\n",
      "| 2000|  Komal|  82000|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0ede4e8-b468-479b-a3c0-0fb8a41d9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"delimiter\",\"\\t\").load(\"file:///C:/Users/aksha/Pyspark/tabData.log\") #.selectExpr(\"_c0 as ID\",\"_c1 as NAME\",\"_c2 as SAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a3e9237-a87e-4542-b1b6-01729fd35f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec98b261-0d9d-4c0a-862c-c526dfdda3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-------+\n",
      "|EMPID|  ENAME|ESALARY|\n",
      "+-----+-------+-------+\n",
      "| 1111|  VVRaj|  12000|\n",
      "| 1331|Krishna|  14000|\n",
      "| 1551|   Mike|  16000|\n",
      "| 1002|  Ramya|  24000|\n",
      "| 1900| Rakesh|  34000|\n",
      "| 1455| Dr.Ali|  90000|\n",
      "| 8005|Mounika|  24000|\n",
      "| 1006| Sourav|  26000|\n",
      "| 1007|   Siya|  98000|\n",
      "| 1008| Bhavya|  30000|\n",
      "| 1009|Trinath|  34000|\n",
      "| 2000|  Komal|  82000|\n",
      "+-----+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20b55017-c51c-4162-8b57-886e0108bcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDF = spark.read.json(\"file:///C:/Users/aksha/Pyspark/edetails.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed64e81a-4efe-4019-8535-c821c292e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------+----------------+-----+\n",
      "|             address|      city|          dept|            name|  sal|\n",
      "+--------------------+----------+--------------+----------------+-----+\n",
      "|[{\"hno\":\"1-41-165\"}]| newjersey|          NULL|          Martin|80000|\n",
      "|                NULL|   newyork|          NULL|            Mike|75000|\n",
      "|                NULL|      peru|     LOGISTICS|          Andrew|87000|\n",
      "|                NULL|      NULL|           HRD|           Teena|57000|\n",
      "|                 USA| elizabeth|          NULL|           clark|92000|\n",
      "|                NULL|    boston|          NULL|          Aneesh|65000|\n",
      "|                NULL|   atlanta|     TRANSPORT|           chloe|78000|\n",
      "|                NULL|      NULL|     MARKETING|          Aakash|77000|\n",
      "|                 USA|jerseycity|          NULL|          daniel|82000|\n",
      "|                NULL|    Vienna|          NULL|         Richard|63000|\n",
      "|                NULL|  Dornbirn|   IMMIGRATION|          Faisal|71000|\n",
      "|                NULL|      NULL|  FOREIGNTRADE|          Justin|59000|\n",
      "|                  UK|losangeles|          NULL|        Flexmala|92000|\n",
      "|                NULL|   chicago|          NULL|           Glenn|53000|\n",
      "|                NULL|  Dornbirn|PUBLIC AFFAIRS|    robert frost|71000|\n",
      "|                NULL|      NULL|      CLINICAL|sabastian edward|67000|\n",
      "+--------------------+----------+--------------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31f900ab-4b52-4802-ba3b-fa9be3a4685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------+----------------+-----+\n",
      "|             address|      city|          dept|            name|  sal|\n",
      "+--------------------+----------+--------------+----------------+-----+\n",
      "|[{\"hno\":\"1-41-165\"}]| newjersey|     TEST_DEPT|          Martin|80000|\n",
      "|                NULL|   newyork|     TEST_DEPT|            Mike|75000|\n",
      "|                NULL|      peru|     LOGISTICS|          Andrew|87000|\n",
      "|                NULL|      NULL|           HRD|           Teena|57000|\n",
      "|                 USA| elizabeth|     TEST_DEPT|           clark|92000|\n",
      "|                NULL|    boston|     TEST_DEPT|          Aneesh|65000|\n",
      "|                NULL|   atlanta|     TRANSPORT|           chloe|78000|\n",
      "|                NULL|      NULL|     MARKETING|          Aakash|77000|\n",
      "|                 USA|jerseycity|     TEST_DEPT|          daniel|82000|\n",
      "|                NULL|    Vienna|     TEST_DEPT|         Richard|63000|\n",
      "|                NULL|  Dornbirn|   IMMIGRATION|          Faisal|71000|\n",
      "|                NULL|      NULL|  FOREIGNTRADE|          Justin|59000|\n",
      "|                  UK|losangeles|     TEST_DEPT|        Flexmala|92000|\n",
      "|                NULL|   chicago|     TEST_DEPT|           Glenn|53000|\n",
      "|                NULL|  Dornbirn|PUBLIC AFFAIRS|    robert frost|71000|\n",
      "|                NULL|      NULL|      CLINICAL|sabastian edward|67000|\n",
      "+--------------------+----------+--------------+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.na.fill(\"TEST_DEPT\",\"dept\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f19781db-4103-451b-a506-27f2cf09cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to fill 2 different columns with null values\n",
    "#jsonDF.na.fill({\"dept\":\"TEST_DEPT\",\"city\":\"USA\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bfe2d15-1437-4cc8-910d-fc4082da330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = sc.textFile(\"file:///C:/Users/aksha/Pyspark/hivejoinData.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7037970-0b0e-434e-ac23-b93fb84a7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata = data1.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9065556f-0166-4f0b-bcd3-eab2fd24db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"loc\", StringType(), True),\n",
    "    StructField(\"pan\", StringType(), True),\n",
    "    StructField(\"yrsOfExp\", DoubleType(), True),\n",
    "    StructField(\"skillset\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbccd307-d7e2-4404-b3b3-ca2220424f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingFile = cdata.map(lambda x: (int(x[0]),\n",
    "                                     x[1],\n",
    "                                     x[2],\n",
    "                                     x[3],\n",
    "                                     float(x[4].strip()) if x[4].strip().replace('.','').isdigit() else 0.0,\n",
    "                                     x[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdc6c6c4-1e42-4e35-af78-4199343eaf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(mappingFile, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f100ec3-dab7-4d2e-8bc7-ec1b6a46f9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+----------+--------+--------+\n",
      "| id|   name|      loc|       pan|yrsOfExp|skillset|\n",
      "+---+-------+---------+----------+--------+--------+\n",
      "|100|  GOPAL|HYDERABAD|AAZPT1234J|    14.0| BIGDATA|\n",
      "|101|   ROJA|BANGALORE|AZJJI2324N|    13.0|     SAP|\n",
      "|102| RAKESH|  CHENNAI|JIRTY2034N|     9.0|    JAVA|\n",
      "|111|  MANJU|     PUNE|ERYUR6767K|    11.0| DOT NET|\n",
      "|222|  SANJU|   MUMBAI|TRUTY7876B|    10.0|      BI|\n",
      "|333|SHANKAR|HYDERABAD| RTUTL590H|     6.0|     C++|\n",
      "+---+-------+---------+----------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "906c676d-eb3f-4488-b3c1-e54eff8ba596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.parquet(\"file:///C:/Users/aksha/Pyspark/emp/part-00000-9c3ad50f-fba8-4380-824a-9a33a3d95079-c000.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a40b923e-8ae5-41b6-b670-aec853199005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|empid|ename| esal|\n",
      "+-----+-----+-----+\n",
      "|   80|EMP49|49000|\n",
      "|   95|GOPAL|12000|\n",
      "|   99| EMP2|25000|\n",
      "|  100| EMP1|12000|\n",
      "|  101| EMP2|14000|\n",
      "|  102| EMP3|16000|\n",
      "|  103| EMP4|18000|\n",
      "|  104| EMP5|20000|\n",
      "|  105| EMP6|22000|\n",
      "|  106| EMP7|24000|\n",
      "|  107| EMP8|26000|\n",
      "|  108| EMP9|28000|\n",
      "|  109|EMP10|30000|\n",
      "|  110|EMP34|45000|\n",
      "|  114|EMP35|49000|\n",
      "|  115|EMP36|52000|\n",
      "|  116|EMP38|55000|\n",
      "|  117|EMP39|59000|\n",
      "|  118|EMP40|62000|\n",
      "|  119|EMP38|55000|\n",
      "+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38ff6e5f-187a-4996-b537-31a3962fdfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"textTab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c967196-b8af-497a-8d68-58f3e73f35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"parquettab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fdb4808-c3fa-4798-bdcc-73baad2a4885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.sql(\"select    from textTab t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e681f09-546f-4c94-a719-4534a81d47c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "| id|  name|      loc|       pan|yrsOfExp|skillset|empid|ename| esal|\n",
      "+---+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "|100| GOPAL|HYDERABAD|AAZPT1234J|    14.0| BIGDATA|  100| EMP1|12000|\n",
      "|101|  ROJA|BANGALORE|AZJJI2324N|    13.0|     SAP|  101| EMP2|14000|\n",
      "|102|RAKESH|  CHENNAI|JIRTY2034N|     9.0|    JAVA|  102| EMP3|16000|\n",
      "+---+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2,df[\"id\"] == df2[\"empid\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c60bdd42-8869-41a8-bab2-afc4e7351383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df columns: ['id', 'name', 'loc', 'pan', 'yrsOfExp', 'skillset']\n",
      "df2 columns: ['empid', 'ename', 'esal']\n"
     ]
    }
   ],
   "source": [
    "print(\"df columns:\", df.columns)\n",
    "print(\"df2 columns:\", df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdebcf27-a141-4a09-a174-18d3bee5418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---------+----------+--------+--------+-----+-----+-----+\n",
      "| id|   name|      loc|       pan|yrsOfExp|skillset|empid|ename| esal|\n",
      "+---+-------+---------+----------+--------+--------+-----+-----+-----+\n",
      "|100|  GOPAL|HYDERABAD|AAZPT1234J|    14.0| BIGDATA|  100| EMP1|12000|\n",
      "|101|   ROJA|BANGALORE|AZJJI2324N|    13.0|     SAP|  101| EMP2|14000|\n",
      "|102| RAKESH|  CHENNAI|JIRTY2034N|     9.0|    JAVA|  102| EMP3|16000|\n",
      "|111|  MANJU|     PUNE|ERYUR6767K|    11.0| DOT NET| NULL| NULL| NULL|\n",
      "|222|  SANJU|   MUMBAI|TRUTY7876B|    10.0|      BI| NULL| NULL| NULL|\n",
      "|333|SHANKAR|HYDERABAD| RTUTL590H|     6.0|     C++| NULL| NULL| NULL|\n",
      "+---+-------+---------+----------+--------+--------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, df[\"id\"] == df2[\"empid\"],\"left_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3d10db2-f4db-4b36-8ce2-80657a4bd1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "|  id|  name|      loc|       pan|yrsOfExp|skillset|empid|ename| esal|\n",
      "+----+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  108| EMP9|28000|\n",
      "| 101|  ROJA|BANGALORE|AZJJI2324N|    13.0|     SAP|  101| EMP2|14000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  115|EMP36|52000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  103| EMP4|18000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  117|EMP39|59000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  107| EMP8|26000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  114|EMP35|49000|\n",
      "| 100| GOPAL|HYDERABAD|AAZPT1234J|    14.0| BIGDATA|  100| EMP1|12000|\n",
      "| 102|RAKESH|  CHENNAI|JIRTY2034N|     9.0|    JAVA|  102| EMP3|16000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|   80|EMP49|49000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|   95|GOPAL|12000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  109|EMP10|30000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  105| EMP6|22000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  110|EMP34|45000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  106| EMP7|24000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  116|EMP38|55000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  119|EMP38|55000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  118|EMP40|62000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|   99| EMP2|25000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  104| EMP5|20000|\n",
      "+----+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, df[\"id\"] == df2[\"empid\"],\"right_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "090a9486-ac7f-48e4-b072-7b34305714ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "|  id|  name|      loc|       pan|yrsOfExp|skillset|empid|ename| esal|\n",
      "+----+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|   80|EMP49|49000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|   95|GOPAL|12000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|   99| EMP2|25000|\n",
      "| 100| GOPAL|HYDERABAD|AAZPT1234J|    14.0| BIGDATA|  100| EMP1|12000|\n",
      "| 101|  ROJA|BANGALORE|AZJJI2324N|    13.0|     SAP|  101| EMP2|14000|\n",
      "| 102|RAKESH|  CHENNAI|JIRTY2034N|     9.0|    JAVA|  102| EMP3|16000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  103| EMP4|18000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  104| EMP5|20000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  105| EMP6|22000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  106| EMP7|24000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  107| EMP8|26000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  108| EMP9|28000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  109|EMP10|30000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  110|EMP34|45000|\n",
      "| 111| MANJU|     PUNE|ERYUR6767K|    11.0| DOT NET| NULL| NULL| NULL|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  114|EMP35|49000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  115|EMP36|52000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  116|EMP38|55000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  117|EMP39|59000|\n",
      "|NULL|  NULL|     NULL|      NULL|    NULL|    NULL|  118|EMP40|62000|\n",
      "+----+------+---------+----------+--------+--------+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df2, df[\"id\"] == df2[\"empid\"],\"full_outer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b23b9ef-8c74-4b67-9a2c-90aad7b88367",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf = spark.read.json(\"file:///C:/Users/aksha/Pyspark/ComplexJsonData.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "899d58fc-294d-4ead-9134-03c7544a8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# withColumn returns a new DataFrame with an added column, typically after performing a column operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaf20429-8cc3-42bf-8abe-e9828c9aeab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- instid: long (nullable = true)\n",
      " |-- instname: string (nullable = true)\n",
      " |-- inststatus: string (nullable = true)\n",
      " |-- pathdet: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- docid: long (nullable = true)\n",
      " |    |    |-- enddate: string (nullable = true)\n",
      " |    |    |-- plnstid: long (nullable = true)\n",
      " |    |    |-- startdate: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      " |    |    |-- workitemid: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datadf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d414836-76c0-457c-ad33-b41b16e4e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+--------------------+\n",
      "|instid|       instname|inststatus|             pathdet|\n",
      "+------+---------------+----------+--------------------+\n",
      "| 12345|789654123125485|  Released|[{52312, 2017-12-...|\n",
      "| 12347|789654123135452|   Pending|[{52315, 2017-12-...|\n",
      "+------+---------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datadf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7a83a7e4-e5c4-4e03-a75f-dac9c62087a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata1 = datadf.withColumn(\"pathdet1\",explode(col(\"pathdet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18ff4fe4-ed17-4475-b98f-7c1b073b969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- instid: long (nullable = true)\n",
      " |-- instname: string (nullable = true)\n",
      " |-- inststatus: string (nullable = true)\n",
      " |-- pathdet: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- docid: long (nullable = true)\n",
      " |    |    |-- enddate: string (nullable = true)\n",
      " |    |    |-- plnstid: long (nullable = true)\n",
      " |    |    |-- startdate: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      " |    |    |-- workitemid: long (nullable = true)\n",
      " |-- pathdet1: struct (nullable = true)\n",
      " |    |-- docid: long (nullable = true)\n",
      " |    |-- enddate: string (nullable = true)\n",
      " |    |-- plnstid: long (nullable = true)\n",
      " |    |-- startdate: string (nullable = true)\n",
      " |    |-- username: string (nullable = true)\n",
      " |    |-- workitemid: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdata1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95f73aaf-7862-4c53-a341-9e5304efa5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+--------------------+--------------------+\n",
      "|instid|       instname|inststatus|             pathdet|            pathdet1|\n",
      "+------+---------------+----------+--------------------+--------------------+\n",
      "| 12345|789654123125485|  Released|[{52312, 2017-12-...|{52312, 2017-12-0...|\n",
      "| 12345|789654123125485|  Released|[{52312, 2017-12-...|{52312, 2017-12-0...|\n",
      "| 12345|789654123125485|  Released|[{52312, 2017-12-...|{52312, 2017-12-0...|\n",
      "| 12347|789654123135452|   Pending|[{52315, 2017-12-...|{52315, 2017-12-0...|\n",
      "| 12347|789654123135452|   Pending|[{52315, 2017-12-...|{52315, , 12347, ...|\n",
      "+------+---------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdata1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fa0a9a5-f1d6-4f15-a834-5b1e59044fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdata2 = dfdata1.select(\"instid\",\"instname\", \"inststatus\", col(\"pathdet1.docid\").alias(\"docid\"),col(\"pathdet1.workitemid\").alias(\"workitemid\"),\n",
    "    col(\"pathdet1.username\").alias(\"username\"), col(\"pathdet1.startdate\").alias(\"startdate\"),col(\"pathdet1.enddate\").alias(\"enddate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34e060f7-6000-4df9-a2ba-cf5bda352729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- instid: long (nullable = true)\n",
      " |-- instname: string (nullable = true)\n",
      " |-- inststatus: string (nullable = true)\n",
      " |-- docid: long (nullable = true)\n",
      " |-- workitemid: long (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- startdate: string (nullable = true)\n",
      " |-- enddate: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdata2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a352b20-5880-4a2d-850c-de41442e4a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+----------+-----+----------+--------+-------------------+-------------------+\n",
      "|instid|       instname|inststatus|docid|workitemid|username|          startdate|            enddate|\n",
      "+------+---------------+----------+-----+----------+--------+-------------------+-------------------+\n",
      "| 12345|789654123125485|  Released|52312|       235|     dex|2017-12-01 15:05:23|2017-12-01 15:05:56|\n",
      "| 12345|789654123125485|  Released|52312|       236|     dex|2017-12-01 15:05:56|2017-12-01 15:06:23|\n",
      "| 12345|789654123125485|  Released|52312|       238|     mhx|2017-12-01 15:06:23|2017-12-01 15:06:45|\n",
      "| 12347|789654123135452|   Pending|52315|       242|     dex|2017-12-01 15:07:45|2017-12-01 15:08:31|\n",
      "| 12347|789654123135452|   Pending|52315|       244|     dex|2017-12-01 15:08:31|                   |\n",
      "+------+---------------+----------+-----+----------+--------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdata2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df7bce45-6340-44d6-8ae8-1c3f2c4f91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "person_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"address\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4560e523-8dcc-4019-a862-b38ed16c7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"Raja\", 21, \"HYD\"),\n",
    "    (\"Ramya\", 34, \"BAN\"),\n",
    "    (\"Rani\", 30, \"MUM\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f96fa7f3-b804-434e-91e1-f8a2633d5aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data, person_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20a97068-739d-4433-a6e6-60d49e42ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+\n",
      "| name|age|address|\n",
      "+-----+---+-------+\n",
      "| Raja| 21|    HYD|\n",
      "|Ramya| 34|    BAN|\n",
      "| Rani| 30|    MUM|\n",
      "+-----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41ca5caa-7864-45b5-8324-9d6149489953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-------+\n",
      "| name|age|address|\n",
      "+-----+---+-------+\n",
      "|Ramya| 34|    BAN|\n",
      "| Rani| 30|    MUM|\n",
      "+-----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"age > 25\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ed0cb-004e-47d6-bbf9-2bf0001af6bd",
   "metadata": {},
   "source": [
    "## Converting dataframe to dataset \n",
    "Python does not support Datasets but only supports datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c5427ec-b723-47c3-b09a-2fe3ef47677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"file:///C:/Users/aksha/Pyspark/InputData.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d60df22-46ad-4d44-9e7a-51c8c89de9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address', 'Age', 'Desg', 'State', 'YrsOfExp', 'name']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1926c54-1cdc-4f79-8555-0e9db438ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9b7705d-ed19-4083-8f8b-4ff62eb1adc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Address', 'Age', 'Desg', 'State', 'YrsOfExp', 'name']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a4b3a6dd-af56-4999-a1c5-afc3aee5852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+--------------+-------------+--------+------------+\n",
      "|    Address| Age|          Desg|        State|YrsOfExp|        name|\n",
      "+-----------+----+--------------+-------------+--------+------------+\n",
      "|  Hyderabad|NULL|           STA|    Telangana|    12.5|       Gopal|\n",
      "|  Bangalore|   6|          NULL|    Karnataka|    NULL|     Mounika|\n",
      "|    Chennai|  22|   Sw Engineer|    TamilNadu|     1.2|       Ramya|\n",
      "|  Hyderabad|NULL|            TA|    Telangana|    12.5|      Sekhar|\n",
      "|  Bangalore|  12|          NULL|    Karnataka|    NULL|      Reshma|\n",
      "|       Pune|  22|   Sw Engineer|   Maharastra|     1.2|       Ramya|\n",
      "|  Hyderabad|NULL|Senior Analyst|    Telangana|     9.5| Ravichandra|\n",
      "|  Bangalore|  18|          NULL|    Karnataka|    NULL|     Meghana|\n",
      "|      Delhi|  22|   Sw Engineer|        Delhi|     1.2|      Ravali|\n",
      "|  Hyderabad|NULL|           STA|    Telangana|    12.5| MahaLakshmi|\n",
      "|  Bangalore|   6|          NULL|    Karnataka|    NULL|SouravMishra|\n",
      "|     Indore|  22|   Sw Engineer|MadhyaPradesh|     1.2|       Ramya|\n",
      "|  Hyderabad|NULL|           STA|    Telangana|    12.5|       Gopal|\n",
      "|  Bangalore|  34|          NULL|    Karnataka|    NULL|     Mounika|\n",
      "|    Chennai|  22|   Sw Engineer|AndhraPradesh|     1.2|       Ramya|\n",
      "|  Hyderabad|NULL|           STA|    Telangana|    12.5|       Gopal|\n",
      "|  Hyderabad|  40|          NULL|    Telangana|    NULL|     Raghava|\n",
      "|    Chennai|  32|          NULL|    Telangana|    NULL|       Raaji|\n",
      "|   Warangal|NULL|           STA|    Telangana|    12.5|       Gopal|\n",
      "|Tiruvendram|  38|          NULL|       Kerala|    NULL|   Mahildhar|\n",
      "+-----------+----+--------------+-------------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef91ca7-6077-4c0d-8324-ebe66c5c7ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3.11",
   "language": "python",
   "name": "pyspark3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
